{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-T4Ex4EDi0j-GR07J6p6DAL1mCxZ8_PK",
      "authorship_tag": "ABX9TyPZTAjfYNG3QPF5eS2ORRdz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!!pip install dspy\n",
        "!!pip install --upgrade dspy"
      ],
      "metadata": {
        "id": "x87UVFDQqcJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_path = \"/content/drive/MyDrive/arbigent/arbigent-results/feedback-result\""
      ],
      "metadata": {
        "id": "oTGE0ZChLVLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "lm = dspy.LM('openai/gpt-4o-mini')\n",
        "dspy.configure(lm=lm)"
      ],
      "metadata": {
        "id": "b1FNg0OI3uq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "BFUJb70cfj0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG5N6u9GklwG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "from pprint import pprint\n",
        "import dspy\n",
        "from dspy import Example\n",
        "from dspy.teleprompt import COPRO\n",
        "from dspy.primitives import Prediction\n",
        "\n",
        "class ActionSchema(dspy.Signature):\n",
        "    \"\"\"Schema for generating agent actions\"\"\"\n",
        "    image_description = dspy.OutputField(desc=\"Detailed description of current screen\")\n",
        "    memo = dspy.OutputField(desc=\"Notes about the next action to take\")\n",
        "    action = dspy.OutputField(\n",
        "        desc=\"Action to execute\",\n",
        "        choices=[\"ClickWithIndex\", \"InputText\", \"BackPress\", \"KeyPress\", \"Scroll\", \"Wait\", \"GoalAchieved\", \"Failed\"]\n",
        "    )\n",
        "    text = dspy.OutputField(desc=\"Additional text for the action\", nullable=True)\n",
        "\n",
        "class AgentSignature(dspy.Signature):\n",
        "    \"\"\"Take a deep breath. You are an agent that achieves the user's goal automatically. Please don't do anything the user doesn't want to do. Please be careful not to repeat the same action. It's better to achieve users' goals with the fewest number of actions.\"\"\"\n",
        "    image = dspy.InputField(desc=\"Base64 encoded image of the current screen\", type=dspy.Image)\n",
        "    text = dspy.InputField(desc=\"User's input text including goal and UI state\")\n",
        "    output:ActionSchema = dspy.OutputField(type=ActionSchema, desc=\"Generated action\")\n",
        "\n",
        "\n",
        "def load_training_data(yml_path, jsonls_dir):\n",
        "    \"\"\"Load training data from YAML and JSONL files\"\"\"\n",
        "    with open(yml_path, \"r\") as f:\n",
        "        data = yaml.safe_load(f)\n",
        "\n",
        "    step_ids = [fb['stepId'] for fb in data.get(\"stepFeedbacks\", []) if fb.get(\"type\") == \"Good\"]\n",
        "\n",
        "    examples = []\n",
        "    for step_id in step_ids:\n",
        "        jsonl_path = os.path.join(jsonls_dir, f\"{step_id}.jsonl\")\n",
        "        if not os.path.exists(jsonl_path):\n",
        "            continue\n",
        "\n",
        "        with open(jsonl_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    record = json.loads(line)\n",
        "\n",
        "                    user_msg = next(m for m in record[\"requestBody\"][\"messages\"] if m[\"role\"] == \"user\")\n",
        "\n",
        "                    # Get image URL (base64)\n",
        "                    image_content = next(c for c in user_msg[\"content\"] if c[\"type\"] == \"image_url\")\n",
        "                    image = dspy.Image.from_url(image_content[\"image_url\"][\"url\"])\n",
        "\n",
        "                    text_content = next(c for c in user_msg[\"content\"] if c[\"type\"] == \"text\")\n",
        "                    text = text_content[\"text\"]\n",
        "\n",
        "                    response = json.loads(record[\"responseBody\"][\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "                    examples.append(Example(\n",
        "                        image=image,\n",
        "                        text=text,\n",
        "                        output=response\n",
        "                    ).with_inputs(\"image\", \"text\"))\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {step_id}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    return examples\n",
        "\n",
        "def action_validator(example, pred, trace=None):\n",
        "    # Response comparison\n",
        "    expected = example.output\n",
        "    print(\"raw output\", pred.output)\n",
        "    predicted = pred.output\n",
        "    # predicted = json.loads(pred.output)\n",
        "    # print(\"parsed output\", predicted)\n",
        "\n",
        "    # Action match check\n",
        "    action_match = (expected[\"action\"].lower() == predicted.action.lower())\n",
        "\n",
        "    # Text field partial match\n",
        "    text_match = (str(expected.get(\"text\", \"\")).lower() == str(predicted.text).lower())\n",
        "    print(\"predicted image_description:\", predicted.image_description)\n",
        "    print(\"expected image_description:\", expected.get(\"image_description\", \"\"))\n",
        "    if(not(action_match)):\n",
        "        print(\"action_match: \", action_match)\n",
        "        print(\"expected: \", expected[\"action\"])\n",
        "        print(\"predicted: \", predicted.action)\n",
        "    if(not(text_match)):\n",
        "        print(\"text_match: \", text_match)\n",
        "        print(\"expected: \", expected.get(\"text\", \"\").lower() )\n",
        "        print(\"predicted: \", predicted.text.lower())\n",
        "\n",
        "    return action_match and text_match\n",
        "\n",
        "\n",
        "base_optimizer = dspy.Predict(AgentSignature)\n",
        "\n",
        "def optimize_prompt(yml_path, jsonls_dir):\n",
        "\n",
        "    train_examples = load_training_data(yml_path, jsonls_dir)\n",
        "\n",
        "\n",
        "    optimizer = COPRO(\n",
        "        metric=action_validator,\n",
        "        prompt_model=dspy.LM('openai/gpt-4o-mini'),\n",
        "        breadth=4,\n",
        "        depth=4,\n",
        "        init_temperature=1.2,\n",
        "        max_retries=5,\n",
        "    )\n",
        "\n",
        "    # Run optimization\n",
        "    optimized_module = optimizer.compile(\n",
        "        base_optimizer,\n",
        "        trainset=train_examples,\n",
        "        eval_kwargs={'num_threads': 1, 'display_progress': True}\n",
        "    )\n",
        "\n",
        "    return optimized_module\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    yml_path = result_path + \"/result.yml\"\n",
        "    jsonls_dir = result_path + \"/jsonls\"\n",
        "\n",
        "    optimized = optimize_prompt(yml_path, jsonls_dir)\n",
        "\n",
        "    optimized.save(\"optimized_prompt.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(base_optimizer)\n",
        "pprint(optimized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv-zXrHgfw2f",
        "outputId": "fb999166-0f82-4253-9d03-c62411cad000"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict(AgentSignature(image, text -> output\n",
            "    instructions=\"Take a deep breath. You are an agent that achieves the user's goal automatically. Please don't do anything the user doesn't want to do. Please be careful not to repeat the same action. It's better to achieve users' goals with the fewest number of actions.\"\n",
            "    image = Field(annotation=str required=True json_schema_extra={'desc': 'Base64 encoded image of the current screen', '__dspy_field_type': 'input', 'prefix': 'Image:'})\n",
            "    text = Field(annotation=str required=True json_schema_extra={'desc': \"User's input text including goal and UI state\", '__dspy_field_type': 'input', 'prefix': 'Text:'})\n",
            "    output = Field(annotation=ActionSchema required=True json_schema_extra={'desc': 'Generated action', '__dspy_field_type': 'output', 'prefix': 'Output:'})\n",
            "))\n",
            "Predict(StringSignature(image, text -> output\n",
            "    instructions=\"As an intuitive agent, your primary mission is to seamlessly empower users toward their goals while being acutely aware of their preferences and needs. Carefully tailor your approach by anticipating what the user might want, ensuring clarity in communication and eliminating redundancy. Execute actions with maximum efficiency, minimizing steps, and adjusting dynamically based on the user's feedback or directional change. Aim purely to realize the userâ€™s objectives without imposing any unwanted activities upon them, which will foster a cooperative and productive environment.\"\n",
            "    image = Field(annotation=str required=True json_schema_extra={'desc': 'Base64 encoded image of the current screen', '__dspy_field_type': 'input', 'prefix': 'Image:'})\n",
            "    text = Field(annotation=str required=True json_schema_extra={'desc': \"User's input text including goal and UI state\", '__dspy_field_type': 'input', 'prefix': 'Text:'})\n",
            "    output = Field(annotation=ActionSchema required=True json_schema_extra={'desc': 'Generated action', '__dspy_field_type': 'output', 'prefix': \"Please summarize the streamlined, step-by-step actions you would take to efficiently reach the user's desired outcome while prioritizing their preferences.\"})\n",
            "))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples = load_training_data(yml_path, jsonls_dir)\n",
        "base_scores = []\n",
        "for x in train_examples:\n",
        "    pred = base_optimizer(**x.inputs())\n",
        "    score = action_validator(x, pred)\n",
        "    base_scores.append(score)\n",
        "\n",
        "base_accuracy = base_scores.count(True) / len(base_scores)\n",
        "print(\"Base Accuracy: \", base_accuracy)\n",
        "\n",
        "copro_scores = []\n",
        "for x in train_examples:\n",
        "    pred = optimized(**x.inputs())\n",
        "    score = action_validator(x, pred)\n",
        "    copro_scores.append(score)\n",
        "\n",
        "copro_scores = copro_scores.count(True) / len(copro_scores)\n",
        "print(\"CORPO Accuracy: \", copro_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GFJoDhck5Qe",
        "outputId": "bff68b7b-4c8b-4ee1-9b36-32762824be23"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw output image_description='The Settings menu is displayed with options for Network & internet, Connected devices, Apps, and Notifications. There is a search bar at the top.' memo=\"Next, I will click on the 'Apps' option to continue navigating towards the 'About emulated device' page.\" action='ClickWithIndex' text='4'\n",
            "predicted image_description: The Settings menu is displayed with options for Network & internet, Connected devices, Apps, and Notifications. There is a search bar at the top.\n",
            "expected image_description: \n",
            "text_match:  False\n",
            "expected:  1\n",
            "predicted:  4\n",
            "raw output image_description=\"The screen displays information about an emulated device, including the device name, Google account, and phone number. There is an option for 'Legal information' at the bottom.\" memo=\"Click on the 'Legal information' option to proceed.\" action='ClickWithIndex' text='3'\n",
            "predicted image_description: The screen displays information about an emulated device, including the device name, Google account, and phone number. There is an option for 'Legal information' at the bottom.\n",
            "expected image_description: \n",
            "raw output image_description='Android settings screen displaying options for Passwords, passkeys & accounts, Digital Wellbeing & parental controls, Google, System, About emulated device, and Tips & support.' memo=\"User is on the right track to find 'About emulated device'. The next step is to click on it to access the page.\" action='ClickWithIndex' text='5'\n",
            "predicted image_description: Android settings screen displaying options for Passwords, passkeys & accounts, Digital Wellbeing & parental controls, Google, System, About emulated device, and Tips & support.\n",
            "expected image_description: \n",
            "raw output image_description=\"The screen displays a prompt asking if the user wants to remember photo locations, with a checkbox already checked for tagging photos and videos with their locations. There is a 'NEXT' button at the bottom.\" memo='Proceed to the next step to open the camera app.' action='ClickWithIndex' text='1'\n",
            "predicted image_description: The screen displays a prompt asking if the user wants to remember photo locations, with a checkbox already checked for tagging photos and videos with their locations. There is a 'NEXT' button at the bottom.\n",
            "expected image_description: \n",
            "raw output image_description=\"The screen shows a prompt with an option to remember photo locations with a checkbox already selected and a 'NEXT' button at the bottom.\" memo=\"To proceed past the screen and move closer to the goal of opening the camera, click the 'Next' button to navigate forward from this prompt.\" action='ClickWithIndex' text='1'\n",
            "predicted image_description: The screen shows a prompt with an option to remember photo locations with a checkbox already selected and a 'NEXT' button at the bottom.\n",
            "expected image_description: \n",
            "text_match:  False\n",
            "expected:  4\n",
            "predicted:  1\n",
            "raw output image_description='The camera app interface is displayed, showing a pixelated green character and options to switch between camera and video modes. The camera mode is currently selected.' memo='To proceed with opening the camera app, click on the option to switch to camera mode.' action='ClickWithIndex' text='0'\n",
            "predicted image_description: The camera app interface is displayed, showing a pixelated green character and options to switch between camera and video modes. The camera mode is currently selected.\n",
            "expected image_description: \n",
            "action_match:  False\n",
            "expected:  GoalAchieved\n",
            "predicted:  ClickWithIndex\n",
            "text_match:  False\n",
            "expected:  \n",
            "predicted:  0\n",
            "Base Accuracy:  0.5\n",
            "raw output image_description='The settings menu is displayed with options for Network & internet, Connected devices, Apps, and Notifications. A search bar is also present at the top.' memo=\"Click on the 'Search settings' field to input text for searching.\" action='ClickWithIndex' text='1'\n",
            "predicted image_description: The settings menu is displayed with options for Network & internet, Connected devices, Apps, and Notifications. A search bar is also present at the top.\n",
            "expected image_description: \n",
            "raw output image_description=\"The screen displays information about an emulated device, including the device name, Google account, and phone number. There is an option for 'Legal information' that is clickable.\" memo=\"Click on 'Legal information' to proceed.\" action='ClickWithIndex' text='3'\n",
            "predicted image_description: The screen displays information about an emulated device, including the device name, Google account, and phone number. There is an option for 'Legal information' that is clickable.\n",
            "expected image_description: \n",
            "raw output image_description='Android settings screen displaying options for Passwords, passkeys & accounts, Digital Wellbeing & parental controls, Google, System, About emulated device, and Tips & support.' memo=\"User is close to achieving their goal. The next step is to click on 'About emulated device' to reach the desired page.\" action='ClickWithIndex' text='5'\n",
            "predicted image_description: Android settings screen displaying options for Passwords, passkeys & accounts, Digital Wellbeing & parental controls, Google, System, About emulated device, and Tips & support.\n",
            "expected image_description: \n",
            "raw output image_description=\"The screen displays a prompt asking if the user wants to remember photo locations, with a checkbox checked for tagging photos and videos with their locations. There is a 'NEXT' button at the bottom.\" memo='Proceed to the next step to open the camera app.' action='ClickWithIndex' text='1'\n",
            "predicted image_description: The screen displays a prompt asking if the user wants to remember photo locations, with a checkbox checked for tagging photos and videos with their locations. There is a 'NEXT' button at the bottom.\n",
            "expected image_description: \n",
            "raw output image_description=\"The screen shows a prompt with an option to remember photo locations with a checkbox already selected and a 'NEXT' button at the bottom.\" memo=\"To proceed past the screen and move closer to the goal of opening the camera, click the 'Next' button to navigate forward from this prompt.\" action='ClickWithIndex' text='1'\n",
            "predicted image_description: The screen shows a prompt with an option to remember photo locations with a checkbox already selected and a 'NEXT' button at the bottom.\n",
            "expected image_description: \n",
            "text_match:  False\n",
            "expected:  4\n",
            "predicted:  1\n",
            "raw output image_description='The camera interface is displayed with a pixelated green character on the left side. There are options to switch between camera and video modes, and a shutter button at the bottom. The interface appears to be ready for taking photos or videos.' memo='To proceed with opening the camera app, click on the option to switch to the camera mode.' action='ClickWithIndex' text='0'\n",
            "predicted image_description: The camera interface is displayed with a pixelated green character on the left side. There are options to switch between camera and video modes, and a shutter button at the bottom. The interface appears to be ready for taking photos or videos.\n",
            "expected image_description: \n",
            "action_match:  False\n",
            "expected:  GoalAchieved\n",
            "predicted:  ClickWithIndex\n",
            "text_match:  False\n",
            "expected:  \n",
            "predicted:  0\n",
            "CORPO Accuracy:  0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm.inspect_history(5)"
      ],
      "metadata": {
        "id": "TMj60R_-HvfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}